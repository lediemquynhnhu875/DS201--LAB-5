# LAB 5 - Deep Learning trong Khoa há»c Dá»¯ liá»‡u (DS201)

## ğŸ“š Giá»›i thiá»‡u

Lab 5 táº­p trung vÃ o viá»‡c xÃ¢y dá»±ng vÃ  huáº¥n luyá»‡n mÃ´ hÃ¬nh **Transformer Encoder** theo kiáº¿n trÃºc "Attention is All You Need" cho hai bÃ i toÃ¡n xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn tiáº¿ng Viá»‡t:
1. **PhÃ¢n loáº¡i Domain** (Domain Classification)
2. **GÃ¡n nhÃ£n Chuá»—i** (Named Entity Recognition)

---

## ğŸ“‹ Ná»™i dung Lab

### **BÃ i 1: PhÃ¢n loáº¡i Domain trÃªn bá»™ dá»¯ liá»‡u UIT-ViOCD**

#### ğŸ¯ MÃ´ táº£ bÃ i toÃ¡n
XÃ¢y dá»±ng mÃ´ hÃ¬nh phÃ¢n loáº¡i domain (lÄ©nh vá»±c) cá»§a cÃ¡c cÃ¢u bÃ¬nh luáº­n tiáº¿ng Viá»‡t. MÃ´ hÃ¬nh cáº§n xÃ¡c Ä‘á»‹nh cÃ¢u bÃ¬nh luáº­n thuá»™c domain nÃ o trong cÃ¡c domain: `mobile`, `app`, `fashion`, v.v.

#### ğŸ“Š Dá»¯ liá»‡u
- **Nguá»“n**: [UIT-ViOCD](https://drive.google.com/drive/folders/1Lu9axyLkw7dMx80uLRgvCnZsmNzhJWAa?usp=sharing)
- **Cáº¥u trÃºc**:
  - `train.json`: Dá»¯ liá»‡u huáº¥n luyá»‡n
  - `dev.json`: Dá»¯ liá»‡u validation
  - `test.json`: Dá»¯ liá»‡u test
- **Format**:
```json
{
    "0": {
        "review": "gÃ³i hÃ ng cáº©n tháº­n . chÆ¡i pubg...",
        "label": "non-complaint",
        "domain": "mobile"
    }
}
```

#### ğŸ—ï¸ Kiáº¿n trÃºc mÃ´ hÃ¬nh
```
Input Text
    â†“
Embedding Layer (vocab_size â†’ d_model=256)
    â†“
Positional Encoding
    â†“
Encoder Layer 1 (Multi-Head Attention + FFN)
    â†“
Encoder Layer 2 (Multi-Head Attention + FFN)
    â†“
Encoder Layer 3 (Multi-Head Attention + FFN)
    â†“
Global Average Pooling
    â†“
Classification Head (d_model â†’ num_classes)
    â†“
Output: Domain Label
```

#### âš™ï¸ Cáº¥u hÃ¬nh
- **d_model**: 256
- **num_heads**: 8
- **d_ff**: 1024
- **num_layers**: 3
- **max_len**: 128
- **batch_size**: 32
- **learning_rate**: 0.0001
- **dropout**: 0.1

#### ğŸ“ˆ ÄÃ¡nh giÃ¡
- **Metrics**: Accuracy, Precision, Recall, F1-score
- **CÃ´ng cá»¥**: scikit-learn classification_report

#### ğŸš€ CÃ¡ch cháº¡y
```bash
# CÃ i Ä‘áº·t thÆ° viá»‡n
pip install torch numpy scikit-learn matplotlib

# Cháº¡y training
python transformer_classifier.py
```

#### ğŸ“ Output
- `best_model.pt`: Model tá»‘t nháº¥t
- `training_curves.png`: Äá»“ thá»‹ loss vÃ  accuracy
- Classification report trÃªn test set

---

### **BÃ i 2: GÃ¡n nhÃ£n Chuá»—i trÃªn bá»™ dá»¯ liá»‡u PhoNER_COVID19**

#### ğŸ¯ MÃ´ táº£ bÃ i toÃ¡n
XÃ¢y dá»±ng mÃ´ hÃ¬nh Named Entity Recognition (NER) Ä‘á»ƒ nháº­n diá»‡n cÃ¡c thá»±c thá»ƒ trong vÄƒn báº£n tiáº¿ng Viá»‡t liÃªn quan Ä‘áº¿n COVID-19, bao gá»“m: tÃªn ngÆ°á»i, Ä‘á»‹a Ä‘iá»ƒm, ngÃ y thÃ¡ng, tá»• chá»©c, triá»‡u chá»©ng bá»‡nh, v.v.

#### ğŸ“Š Dá»¯ liá»‡u
- **Nguá»“n**: [PhoNER_COVID19](https://github.com/VinAIResearch/PhoNER_COVID19)
- **Cáº¥u trÃºc**:
  - `train_syllable.json`: Dá»¯ liá»‡u huáº¥n luyá»‡n
  - `dev_syllable.json`: Dá»¯ liá»‡u validation
  - `test_syllable.json`: Dá»¯ liá»‡u test
- **Format**: JSON Lines (má»—i dÃ²ng 1 sample)
```json
{"words": ["Bá»™", "Y", "táº¿", "."], "tags": ["B-ORGANIZATION", "I-ORGANIZATION", "I-ORGANIZATION", "O"]}
```

#### ğŸ·ï¸ Entity Tags
| Tag | MÃ´ táº£ | VÃ­ dá»¥ |
|-----|-------|-------|
| `B-PATIENT_ID`, `I-PATIENT_ID` | MÃ£ bá»‡nh nhÃ¢n | 523, BN91 |
| `B-NAME`, `I-NAME` | TÃªn ngÆ°á»i | Nguyá»…n VÄƒn A |
| `B-AGE` | Tuá»•i | 67 tuá»•i |
| `B-GENDER` | Giá»›i tÃ­nh | nam, ná»¯ |
| `B-JOB`, `I-JOB` | Nghá» nghiá»‡p | phi cÃ´ng |
| `B-LOCATION`, `I-LOCATION` | Äá»‹a Ä‘iá»ƒm | TP. HCM, HÃ  Ná»™i |
| `B-ORGANIZATION`, `I-ORGANIZATION` | Tá»• chá»©c | Bá»™ Y táº¿ |
| `B-DATE` | NgÃ y thÃ¡ng | 31/7, ngÃ y 14-4 |
| `B-SYMPTOM_AND_DISEASE`, `I-SYMPTOM_AND_DISEASE` | Triá»‡u chá»©ng/Bá»‡nh | sá»‘t cao, khÃ³ thá»Ÿ |
| `B-TRANSPORTATION`, `I-TRANSPORTATION` | PhÆ°Æ¡ng tiá»‡n | mÃ¡y bay, taxi |
| `O` | KhÃ´ng pháº£i entity | cÃ¡c tá»« khÃ¡c |

#### ğŸ—ï¸ Kiáº¿n trÃºc mÃ´ hÃ¬nh
```
Input Sequence
    â†“
Embedding Layer (vocab_size â†’ d_model=256)
    â†“
Positional Encoding
    â†“
Encoder Layer 1 (Multi-Head Attention + FFN)
    â†“
Encoder Layer 2 (Multi-Head Attention + FFN)
    â†“
Encoder Layer 3 (Multi-Head Attention + FFN)
    â†“
Classification Head (d_model â†’ num_tags) [Token-level]
    â†“
Output: Tag Sequence
```

#### âš™ï¸ Cáº¥u hÃ¬nh

- **d_model**: 256
- **num_heads**: 8
- **d_ff**: 1024
- **num_layers**: 3
- **max_len**: 150
- **batch_size**: 16
- **learning_rate**: 0.0003
- **dropout**: 0.3
- **loss**: Focal Loss (gamma=2.0)
- **optimizer**: AdamW vá»›i weight decay
- **scheduler**: CosineAnnealingWarmRestarts

#### ğŸ“ˆ ÄÃ¡nh giÃ¡
- **Metrics**: Entity-level F1-score, Precision, Recall
- **CÃ´ng cá»¥**: seqeval library
- **LÆ°u Ã½**: Metrics Ä‘Æ°á»£c tÃ­nh theo entity hoÃ n chá»‰nh (B-I matching), khÃ´ng pháº£i token-level

#### ğŸš€ CÃ¡ch cháº¡y

```bash
# CÃ i Ä‘áº·t thÆ° viá»‡n
pip install torch numpy scikit-learn matplotlib seqeval

# Cháº¡y training
python ner_improved_version.py
```

#### ğŸ“ Output
- `best_ner_model_improved.pt`: Model tá»‘t nháº¥t
- `ner_training_curves_improved.png`: Äá»“ thá»‹ training
- Detailed classification report theo tá»«ng entity type

---

## ğŸ”§ Chi tiáº¿t ká»¹ thuáº­t

### 1. Multi-Head Attention
```python
Attention(Q, K, V) = softmax(QK^T / âˆšd_k) V
MultiHead(Q, K, V) = Concat(head_1, ..., head_h) W^O
```
- Sá»­ dá»¥ng 8 attention heads
- Má»—i head cÃ³ dimension d_k = d_model / num_heads = 32

### 2. Positional Encoding
```python
PE(pos, 2i) = sin(pos / 10000^(2i/d_model))
PE(pos, 2i+1) = cos(pos / 10000^(2i/d_model))
```
- Encoding vá»‹ trÃ­ tuyá»‡t Ä‘á»‘i cá»§a tá»« trong cÃ¢u
- GiÃºp model hiá»ƒu thá»© tá»± tá»«

### 3. Feed Forward Network
```python
FFN(x) = max(0, xW_1 + b_1)W_2 + b_2
```
- 2 fully connected layers vá»›i ReLU activation
- d_ff = 1024 (hidden dimension)

### 4. Layer Normalization & Residual Connections
```python
output = LayerNorm(x + Sublayer(x))
```
- Ãp dá»¥ng sau má»—i sub-layer
- GiÃºp training á»•n Ä‘á»‹nh hÆ¡n

---

## ğŸ“Š Káº¿t quáº£ mong Ä‘á»£i

### BÃ i 1: Domain Classification
- **Train Accuracy**: > 90%
- **Test Accuracy**: > 85%
- **Training time**: ~10-15 phÃºt (GPU) / ~30-40 phÃºt (CPU)

### BÃ i 2: Named Entity Recognition
- **Dev F1**: ~0.30-0.40
- **Test F1**: ~0.30-0.40
- **Cáº£i thiá»‡n**: Balanced precision & recall
- **Training time**: ~20-30 phÃºt (GPU) / ~60-90 phÃºt (CPU)

---

## ğŸ› ï¸ Xá»­ lÃ½ cÃ¡c váº¥n Ä‘á» thÆ°á»ng gáº·p

### 1. Class Imbalance (BÃ i 2)
**Váº¥n Ä‘á»**: Tag 'O' chiáº¿m ~80-90% dá»¯ liá»‡u

**Giáº£i phÃ¡p**:
- âœ… Sá»­ dá»¥ng class weights (inverse frequency)
- âœ… Focal Loss Ä‘á»ƒ focus vÃ o hard examples
- âœ… ÄÃ¡nh giÃ¡ báº±ng entity-level F1 thay vÃ¬ accuracy

### 2. Overfitting
**Triá»‡u chá»©ng**: Train loss giáº£m nhÆ°ng dev loss tÄƒng

**Giáº£i phÃ¡p**:
- âœ… TÄƒng dropout (0.2 â†’ 0.3)
- âœ… Weight decay trong optimizer
- âœ… Early stopping
- âœ… Gradient clipping

### 3. Low Performance
**NguyÃªn nhÃ¢n cÃ³ thá»ƒ**:
- Learning rate khÃ´ng phÃ¹ há»£p
- Batch size quÃ¡ nhá»/lá»›n
- Vocabulary quÃ¡ nhá» (min_freq cao)

**Giáº£i phÃ¡p**:
- âœ… Thá»­ cÃ¡c learning rate khÃ¡c nhau
- âœ… Äiá»u chá»‰nh batch size
- âœ… Giáº£m min_freq trong vocabulary

### 4. Memory Error
**Giáº£i phÃ¡p**:
- âœ… Giáº£m batch_size
- âœ… Giáº£m max_len
- âœ… Giáº£m d_model hoáº·c d_ff

---

## ğŸ“– TÃ i liá»‡u tham kháº£o

1. **Paper gá»‘c**: [Attention Is All You Need](https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf)
2. **UIT-ViOCD Dataset**: [Google Drive](https://drive.google.com/drive/folders/1Lu9axyLkw7dMx80uLRgvCnZsmNzhJWAa?usp=sharing)
3. **PhoNER_COVID19**: [GitHub](https://github.com/VinAIResearch/PhoNER_COVID19)
4. **The Illustrated Transformer**: [Blog post](http://jalammar.github.io/illustrated-transformer/)
5. **PyTorch Documentation**: [pytorch.org](https://pytorch.org/docs/stable/index.html)

---

## ğŸ“‚ Cáº¥u trÃºc thÆ° má»¥c

```
LAB5_DS201/
â”œâ”€â”€ README.md
â”‚
â”œâ”€â”€ bai1_domain_classification/
â”‚   â”œâ”€â”€ transformer_classifier.py
â”‚   â”œâ”€â”€ train.json
â”‚   â”œâ”€â”€ dev.json
â”‚   â”œâ”€â”€ test.json
â”‚   â”œâ”€â”€ best_model.pt (sau khi train)
â”‚   â””â”€â”€ training_curves.png (sau khi train)
â”‚
â””â”€â”€ bai2_ner/
    â”œâ”€â”€ ner_improved_version.py 
    â”œâ”€â”€ train_syllable.json
    â”œâ”€â”€ dev_syllable.json
    â”œâ”€â”€ test_syllable.json
    â”œâ”€â”€ best_ner_model.pt (sau khi train)
    â”œâ”€â”€ best_ner_model_improved.pt (sau khi train)
    â””â”€â”€ ner_training_curves_improved.png
```

---

*Lab Ä‘Æ°á»£c thiáº¿t káº¿ bá»Ÿi: LÃª Diá»…m Quá»³nh NhÆ°*  
*MÃ´n: DS201 - Deep Learning trong Khoa há»c Dá»¯ liá»‡u*  
*Há»c ká»³: [HK1]*  
*NÄƒm há»c: [NÄƒm 3]*
