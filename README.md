# LAB 5 - Deep Learning trong Khoa há»c Dá»¯ liá»‡u (DS201)

## ğŸ“š Giá»›i thiá»‡u

Lab 5 táº­p trung vÃ o viá»‡c xÃ¢y dá»±ng vÃ  huáº¥n luyá»‡n mÃ´ hÃ¬nh **Transformer Encoder** theo kiáº¿n trÃºc "Attention is All You Need" cho hai bÃ i toÃ¡n xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn tiáº¿ng Viá»‡t:
1. **PhÃ¢n loáº¡i Domain** (Domain Classification)
2. **GÃ¡n nhÃ£n Chuá»—i** (Named Entity Recognition)

---

## ğŸ“‹ Ná»™i dung Lab

### **BÃ i 1: PhÃ¢n loáº¡i Domain trÃªn bá»™ dá»¯ liá»‡u UIT-ViOCD**

#### ğŸ¯ MÃ´ táº£ bÃ i toÃ¡n
XÃ¢y dá»±ng mÃ´ hÃ¬nh phÃ¢n loáº¡i domain (lÄ©nh vá»±c) cá»§a cÃ¡c cÃ¢u bÃ¬nh luáº­n tiáº¿ng Viá»‡t. MÃ´ hÃ¬nh cáº§n xÃ¡c Ä‘á»‹nh cÃ¢u bÃ¬nh luáº­n thuá»™c domain nÃ o trong cÃ¡c domain: `mobile`, `app`, `fashion`, v.v.

#### ğŸ“Š Dá»¯ liá»‡u
- **Nguá»“n**: [UIT-ViOCD](https://drive.google.com/drive/folders/1Lu9axyLkw7dMx80uLRgvCnZsmNzhJWAa?usp=sharing)
- **Cáº¥u trÃºc**:
  - `train.json`: Dá»¯ liá»‡u huáº¥n luyá»‡n
  - `dev.json`: Dá»¯ liá»‡u validation
  - `test.json`: Dá»¯ liá»‡u test
- **Format**:
```json
{
    "0": {
        "review": "gÃ³i hÃ ng cáº©n tháº­n . chÆ¡i pubg...",
        "label": "non-complaint",
        "domain": "mobile"
    }
}
```

#### ğŸ—ï¸ Kiáº¿n trÃºc mÃ´ hÃ¬nh
```
Input Text
    â†“
Embedding Layer (vocab_size â†’ d_model=256)
    â†“
Positional Encoding
    â†“
Encoder Layer 1 (Multi-Head Attention + FFN)
    â†“
Encoder Layer 2 (Multi-Head Attention + FFN)
    â†“
Encoder Layer 3 (Multi-Head Attention + FFN)
    â†“
Global Average Pooling
    â†“
Classification Head (d_model â†’ num_classes)
    â†“
Output: Domain Label
```

#### âš™ï¸ Cáº¥u hÃ¬nh
- **d_model**: 256
- **num_heads**: 8
- **d_ff**: 1024
- **num_layers**: 3
- **max_len**: 128
- **batch_size**: 32
- **learning_rate**: 0.0001
- **dropout**: 0.1

#### ğŸ“ˆ ÄÃ¡nh giÃ¡
- **Metrics**: Accuracy, Precision, Recall, F1-score
- **CÃ´ng cá»¥**: scikit-learn classification_report

#### ğŸš€ CÃ¡ch cháº¡y
```bash
# CÃ i Ä‘áº·t thÆ° viá»‡n
pip install torch numpy scikit-learn matplotlib

# Cháº¡y training
python transformer_classifier.py
```

#### ğŸ“ Output
- `best_model.pt`: Model tá»‘t nháº¥t
- `training_curves.png`: Äá»“ thá»‹ loss vÃ  accuracy
- Classification report trÃªn test set

---

### **BÃ i 2: GÃ¡n nhÃ£n Chuá»—i trÃªn bá»™ dá»¯ liá»‡u PhoNER_COVID19**

#### ğŸ¯ MÃ´ táº£ bÃ i toÃ¡n
XÃ¢y dá»±ng mÃ´ hÃ¬nh Named Entity Recognition (NER) Ä‘á»ƒ nháº­n diá»‡n cÃ¡c thá»±c thá»ƒ trong vÄƒn báº£n tiáº¿ng Viá»‡t liÃªn quan Ä‘áº¿n COVID-19, bao gá»“m: tÃªn ngÆ°á»i, Ä‘á»‹a Ä‘iá»ƒm, ngÃ y thÃ¡ng, tá»• chá»©c, triá»‡u chá»©ng bá»‡nh, v.v.

#### ğŸ“Š Dá»¯ liá»‡u
- **Nguá»“n**: [PhoNER_COVID19](https://github.com/VinAIResearch/PhoNER_COVID19)
- **Cáº¥u trÃºc**:
  - `train_syllable.json`: Dá»¯ liá»‡u huáº¥n luyá»‡n
  - `dev_syllable.json`: Dá»¯ liá»‡u validation
  - `test_syllable.json`: Dá»¯ liá»‡u test
- **Format**: JSON Lines (má»—i dÃ²ng 1 sample)
```json
{"words": ["Bá»™", "Y", "táº¿", "."], "tags": ["B-ORGANIZATION", "I-ORGANIZATION", "I-ORGANIZATION", "O"]}
```

#### ğŸ·ï¸ Entity Tags
| Tag | MÃ´ táº£ | VÃ­ dá»¥ |
|-----|-------|-------|
| `B-PATIENT_ID`, `I-PATIENT_ID` | MÃ£ bá»‡nh nhÃ¢n | 523, BN91 |
| `B-NAME`, `I-NAME` | TÃªn ngÆ°á»i | Nguyá»…n VÄƒn A |
| `B-AGE` | Tuá»•i | 67 tuá»•i |
| `B-GENDER` | Giá»›i tÃ­nh | nam, ná»¯ |
| `B-JOB`, `I-JOB` | Nghá» nghiá»‡p | phi cÃ´ng |
| `B-LOCATION`, `I-LOCATION` | Äá»‹a Ä‘iá»ƒm | TP. HCM, HÃ  Ná»™i |
| `B-ORGANIZATION`, `I-ORGANIZATION` | Tá»• chá»©c | Bá»™ Y táº¿ |
| `B-DATE` | NgÃ y thÃ¡ng | 31/7, ngÃ y 14-4 |
| `B-SYMPTOM_AND_DISEASE`, `I-SYMPTOM_AND_DISEASE` | Triá»‡u chá»©ng/Bá»‡nh | sá»‘t cao, khÃ³ thá»Ÿ |
| `B-TRANSPORTATION`, `I-TRANSPORTATION` | PhÆ°Æ¡ng tiá»‡n | mÃ¡y bay, taxi |
| `O` | KhÃ´ng pháº£i entity | cÃ¡c tá»« khÃ¡c |

#### ğŸ—ï¸ Kiáº¿n trÃºc mÃ´ hÃ¬nh
```
Input Sequence
    â†“
Embedding Layer (vocab_size â†’ d_model=256)
    â†“
Positional Encoding
    â†“
Encoder Layer 1 (Multi-Head Attention + FFN)
    â†“
Encoder Layer 2 (Multi-Head Attention + FFN)
    â†“
Encoder Layer 3 (Multi-Head Attention + FFN)
    â†“
Classification Head (d_model â†’ num_tags) [Token-level]
    â†“
Output: Tag Sequence
```

#### âš™ï¸ Cáº¥u hÃ¬nh

- **d_model**: 256
- **num_heads**: 8
- **d_ff**: 1024
- **num_layers**: 3
- **max_len**: 150
- **batch_size**: 16
- **learning_rate**: 0.0003
- **dropout**: 0.3
- **loss**: Focal Loss (gamma=2.0)
- **optimizer**: AdamW vá»›i weight decay
- **scheduler**: CosineAnnealingWarmRestarts

#### ğŸ“ˆ ÄÃ¡nh giÃ¡
- **Metrics**: Entity-level F1-score, Precision, Recall
- **CÃ´ng cá»¥**: seqeval library
- **LÆ°u Ã½**: Metrics Ä‘Æ°á»£c tÃ­nh theo entity hoÃ n chá»‰nh (B-I matching), khÃ´ng pháº£i token-level

#### ğŸš€ CÃ¡ch cháº¡y

```bash
# CÃ i Ä‘áº·t thÆ° viá»‡n
pip install torch numpy scikit-learn matplotlib seqeval

# Cháº¡y training
python ner_improved_version.py
```

#### ğŸ“ Output
- `best_ner_model_improved.pt`: Model tá»‘t nháº¥t
- `ner_training_curves_improved.png`: Äá»“ thá»‹ training
- Detailed classification report theo tá»«ng entity type

---

## ğŸ“‚ Cáº¥u trÃºc thÆ° má»¥c

```
LAB5_DS201/
â”œâ”€â”€ README.md
â”‚
â”œâ”€â”€ bai1_domain_classification/
â”‚   â”œâ”€â”€ transformer_classifier.py
â”‚   â”œâ”€â”€ train.json
â”‚   â”œâ”€â”€ dev.json
â”‚   â”œâ”€â”€ test.json
â”‚   â”œâ”€â”€ best_model.pt (sau khi train)
â”‚   â””â”€â”€ training_curves.png (sau khi train)
â”‚
â””â”€â”€ bai2_ner/
    â”œâ”€â”€ ner.py 
    â”œâ”€â”€ train_syllable.json
    â”œâ”€â”€ dev_syllable.json
    â”œâ”€â”€ test_syllable.json
    â”œâ”€â”€ [best_ner_model_improved.pt](https://drive.google.com/file/d/1gtxJlFeIZxAmXfff5fgKImB9OX1KXIdN/view?usp=sharing) (sau khi train)
    â””â”€â”€ ner_training_curves_improved.png (sau khi train)
```

---

*Lab Ä‘Æ°á»£c thiáº¿t káº¿ bá»Ÿi: LÃª Diá»…m Quá»³nh NhÆ°*  
*MÃ´n: DS201 - Deep Learning trong Khoa há»c Dá»¯ liá»‡u*  
*Há»c ká»³: [HK1]*  
*NÄƒm há»c: [NÄƒm 3]*
